Project: Travoca – Real-time Text & Voice Translation App
1. Project Overview

Travoca is a Flutter-based mobile app that allows users to:

Speak or type text in one language.

Translate it into another language.

Output translation in text or voice (TTS) form.

Save translation history (text & voice) in MongoDB Atlas.

Key features:

Real-time translation using translator package (GoogleTranslator).

Voice output using flutter_tts.

History saving in MongoDB Atlas for later viewing.

Tab-based history: Text & voice can be replayed.

Supports multiple languages: English, Hindi, Telugu, Tamil, Urdu, etc.

2. Main Components
Component	Purpose	Packages/Tools Used
Flutter UI	Screens for language selection, translation, and output choice	Flutter Material Widgets
Speech Input (optional)	Recognize user speech	speech_to_text (if used)
Text Translation	Translate text from source language to target language	translator package
Voice Output (TTS)	Play translated text in target language	flutter_tts package
History Management	Save text and voice translation history	mongo_dart package with MongoDB Atlas
Audio Playback	Play previously saved voice translations	audioplayers package
MongoDB Atlas	Cloud database to store translation history	MongoDB Atlas cluster
3. Workflow

User Input

User selects source (fromLanguage) and target language (toLanguage).

User either types or speaks text.

Translation

translator translates text in real-time.

Output Choice

Text Form: Shows translated text and saves to MongoDB.

Voice Form: Plays translated text using flutter_tts and logs a history entry in MongoDB.

Currently, voice is not saved as a physical file, only placeholders are stored in DB.

History

History screen fetches entries from MongoDB.

Text entries: Show translated text.

Voice entries: Play translation using TTS or audio files if saved in future.

4. Problems Faced & Solutions
Problem	Reason	Solution
MongoDB history not visible	User checking wrong cluster/database or using placeholders	Verified MongoDB Atlas cluster, database (travoca), collection (history)
Flutter build fails due to audioplayers version	Version mismatch	Upgraded audioplayers to latest compatible version (6.5.1)
Audio files not saving physically	flutter_tts only streams audio, doesn’t store	Currently placeholders used. Future: save TTS output as real audio files
OnBackInvokedCallback warnings	Android 13+ feature not enabled	Not critical; can enable in manifest if needed
Language codes mismatch	TTS requires locale codes (e.g., 'en-US')	Created _getTtsLocale() function to map languages to TTS codes
5. Key Classes & Functions

MongoService (mongo_service.dart)

static Future<void> addHistory(Map<String, dynamic> entry);
static Future<List<Map<String, dynamic>>> fetchHistory();


Handles all database operations (insert, fetch).

ChooseOutputScreen (choose_output_screen.dart)

_translateText() → Translate input text.

_speak() → Play translated text via TTS and log history.

_saveTextHistory() → Store text translations in MongoDB.

_saveVoiceHistory() → Store voice translations (placeholders currently).

HistoryScreen

Displays tabs for Text and Voice history.

Plays voice entries using audioplayers.

6. Current Limitations

Voice audio is not stored physically yet.

MongoDB shows only placeholders for audio.

Multi-user access is possible if multiple devices use the same cluster credentials.

7. Interview Questions & Answers

Q1. What is the architecture of your app?
A1: It’s a Flutter front-end app with MongoDB Atlas back-end. Translation uses GoogleTranslator API. TTS is handled with flutter_tts. History is saved in MongoDB, fetched and displayed on the HistoryScreen.

Q2. How does text-to-speech (TTS) work in your app?
A2: The flutter_tts package converts translated text into speech in real-time. Currently, the audio is streamed and not saved as a file. The database stores a placeholder path for voice history.

Q3. How is translation handled?
A3: Using the translator package, which is a wrapper around Google Translate API. It takes source text, source language code, and target language code to return translated text.

Q4. How is history stored?
A4: Using mongo_dart to connect Flutter with MongoDB Atlas. Each entry has type, fromLanguage, toLanguage, text/audio path, and timestamp.

Q5. Can multiple users see each other’s data?
A5: Only if all users are connecting with the same MongoDB credentials. Currently, all data is stored in your Atlas cluster, so you can see the data.

Q6. What challenges did you face?
A6:

Version conflicts for audioplayers.

TTS requires correct locale codes.

Real audio files weren’t being saved.

Ensuring MongoDB entries are visible and correctly formatted.

Q7. How would you improve it?
A7:

Save real audio files for replay.

Enable multi-user login and user-based history.

Offline translation using a pre-downloaded translation model.

Q8. What packages did you use and why?
A8:

translator → Translation

flutter_tts → Text-to-Speech

mongo_dart → MongoDB connectivity

audioplayers → Play audio files in history

8. Tips for Expo / Interview

Show live translation demo (type + voice).

Show MongoDB Atlas dashboard with saved entries.

Explain how voice works in real-time and placeholder paths.

Discuss future improvements (saving audio, multi-user support).

Mention problems faced and how you fixed them, shows troubleshooting skills.

✅ With this, you are ready to explain the project technically, show a live demo, and answer related interview questions confidently.

If you want, I can also make a diagram showing the data flow from Flutter → TTS/Translator → MongoDB, which is great for your expo presentation.

Do you want me to make that diagram?

You said:
yes
ChatGPT said:
Share




